---
output: html_document
editor_options:
  chunk_output_type: console
bibliography: references.bib
---


## Introduction

Complexity is an umbrella term for concepts derived from information theory, chaos theory, and fractal mathematics, used to quantify unpredictability, entropy, and/or randomness. Using these methods to characterize physiological signals [a subfield commonly referred to as "fractal physiology", @bassingthwaighte2013fractal] has shown promising results in the assessment and diagnostic of the state and health of living systems [@lau2021brain; @ehlers1995chaos; @goetz2007].

There has been an exponential increase in the number of complexity indices in the past few decades [@yang2013]. Although these new procedures are usually mathematically well-defined and theoretically promising, limited empirical evidence is available to understand their similarities and differences [@lau2021brain; @yang2013]. Moreover, some of these methods are resource-intensive and require long computation times. This complicates their application with techniques that utilise high sampling-rates (e.g., M/EEG) and makes them impractical to implement in real-time settings - such as brain-computer interfaces [@azami2017refined; @manis2018]. As such, having empirical data about the computation time of various complexity indices would prove useful, for instance to objectively guide their selection, especially in contexts where time or computational resources are limited.

Additionally, the lack of a comprehensive open-source and user-friendly software for computing various complexity indices likely contributes to the limited availability of empirical comparison [@flood2021]. Indeed, many complexity indices are only described mathematically in journal articles, with reusable code seldom made available, therefore limiting their further application and validation [@yang2013; @flood2021]. And complexity measures with open-source code implementations are scattered across different packages or scripts, or embedded within a larger goal-directed framework [e.g., *HCTSA*, a time-series comparison tool, @fulcher2017]. To address this lack of unified accessibility, we added a comprehensive set of complexity-related features to *NeuroKit2*, a Python package for physiological signal processing [@Makowski2021neurokit], to provide users with a software to compute a vast amount of complexity indices. The code is designed to be as fast as possible, while still written in pure Python [with the help of standard dependencies such as *NumPy* or *Pandas*, @harris2020array; @mckinney2010data] to maximize the re-usability, transparency, and correctness.

Leveraging this tool, the goal of this study is to empirically compare a large number of complexity indices, inspect how they relate to one another, and derive recommendations for indices selection. More specifically, we will quantify the complexity of various types of signals with varying degrees of noise using 128 of the predominantly used indices that are available for computation using *NeuroKit2*. Note that, even though it is one of the largest comparison to date to our knowledge (and covers the most commonly used metrics), this list is by no means exhaustive: new indices are being developed, such as for instance *symmetropy* [@girault2022]. We will then project the results on a latent space through factor analysis, and review the various indices that we find the most relevant and interesting in regards to their representation of the latent dimensions. This analysis will be complemented by hierarchical clustering. To this end, it should be duly noted that the list of 128 indices used for comparison are by no means exhaustive; more recent tools, such as the aforementioned palindromic analyses were not included in the scope of this study.

## Methods

```{r message=FALSE, warning=FALSE, include=FALSE, results='hide'}
cache <- TRUE
```
```{r signals, message=FALSE, warning=FALSE, fig.height=16, fig.width=10, echo=FALSE, fig.cap = "Different types of simulated signals, to which was added 5 types of noise (violet, blue, white, pink, and brown) with different intensities. For each signal type, the first row shows the signal with a minimal amount of noise, and the last with a maximal amount of noise. We can see that adding Brown noise turns the signal into a Random-walk (i.e., a Brownian motion).", cache=FALSE}
library(tidyverse)
library(easystats)
library(patchwork)

df <- read.csv("data_Signals.csv") |>
  mutate(
    Method = as.factor(Method),
    Noise = as.factor(Noise),
    Noise = fct_recode(Noise, "Violet" = "-2", "Blue" = "-1", "White" = "0", "Pink" = "1", "Brown" = "2"),
    Intensity = as.factor(insight::format_value(Noise_Intensity))
  )

df <- df |>
  filter(Intensity %in% levels(df$Intensity)[c(1, round(length(levels(df$Intensity)) / 3), length(levels(df$Intensity)))])

make_plot <- function(method = "Random-Walk", title = "Random-Walk", color = "red") {
  df |>
    filter(Method == method) |>
    ggplot(aes(x = Duration, y = Signal)) +
    geom_line(color = color, size=0.3) +
    ggside::geom_ysidedensity(aes(x = stat(density))) +
    facet_grid(Intensity ~ Noise, labeller = label_value) +
    labs(y = NULL, title = title, x = NULL) +
    theme_minimal() +
    theme(
      axis.ticks = element_blank(),
      axis.text = element_blank(),
      plot.title = element_text(hjust = 0.5),
      ggside.panel.border = element_blank(),
      ggside.panel.grid = element_blank(),
      ggside.panel.background = element_blank()
    )
}

p1 <- make_plot(method = "Random-Walk", title = "Random-Walk", color = "#795548")
p2 <- make_plot(method = "lorenz_10_2.5_28", title = "Lorenz (\u03c3=10, \u03B2=2.5, \u03C1=28)", color = "#FF5722")
p3 <- make_plot(method = "lorenz_20_2_30", title = "Lorenz (\u03c3=20, \u03B2=2, \u03C1=30)", color = "#E91E63")
p4 <- make_plot(method = "oscillatory", title = "Oscillatory", color = "#2196F3")
p5 <- make_plot(method = "fractal", title = "Fractal", color = "#4CAF50")

p1 / p2 / p3 / p4 / p5 + patchwork::plot_annotation(title = "Examples of Simulated Signals", theme = theme(plot.title = element_text(face = "bold", hjust = 0.5)))

rm(df, p1, p2, p3, p4, p5)
```

The Python script to generate the data can be found at 
**github.com/neuropsychology/NeuroKit/studies/complexity_structure**.


We started by generating 5 types of signals, one random-walk, two oscillatory signals made (with one made of harmonic frequencies that results in a self-repeating - fractal-like - signal), and two complex signals derived from Lorenz systems (with parameters ($\sigma = 10, \beta = 2.5, \rho = 28$); and ($\sigma = 20, \beta = 2, \rho = 30$), respectively). Each of this signal was iteratively generated at 6 different lengths (ranging from 500 to 3000 by 500 samples). The resulting vectors were standardized and each were added 5 types of $(1/f)^\beta$ noise (namely violet $\beta=-2$, blue $\beta=-1$, white $\beta=0$, pink $\beta=1$, and brown $\beta=2$ noise). Each noise type was added at 48 different intensities (linearly ranging from 0.1 to 4). Examples of generated signals are presented in **Figure 1**.

The combination of these parameters resulted in a total of `r 48*6*5*5` signal iterations. For each of them, we computed 128 complexity indices, and additional basic metrics such as the standard deviation (*SD*), the *length* of the signal and its dominant *frequency*. We also included a *random* number to make sure that our our dimensionality analyses accurately discriminate this unrelated feature. The parameters used (such as the time-delay $\tau$ or the embedding dimension) are documented in the data generation script. For a complete description of the various indices included, please refer to NeuroKit's documentation at **https://neuropsychology.github.io/NeuroKit**.

## Results

The data analysis script and the data are fully available at 
**github.com/neuropsychology/NeuroKit/studies/complexity_structure**. 
The analysis was performed in R using the *easystats* collection of packages [@correlationArticle; @seeArticle; @parametersArticle; @modelbasedPackage]. As the results are primarily presented in a graphical way via the figures, the code to fully reproduce them is also included.


```{r message=FALSE, warning=FALSE, results='hide', echo=FALSE}
df <- read.csv("data_Complexity.csv") |>
  mutate(Method = as.factor(Method))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
colors <- c(
  "SD" = "red",
  "Noise" = "red",
  "Length" = "red",
  "Random" = "red",
  "Frequency" = "red",
  "PFD (A)" = "#2196F3",
  "PFD (B)" = "#2196F3",
  "PFD (C)" = "#2196F3",
  "PFD (D)" = "#2196F3",
  "PFD (r)" = "#2196F3",
  "PFD (3)" = "#2196F3",
  "PFD (10)" = "#2196F3",
  "PFD (100)" = "#2196F3",
  "PFD (1000)" = "#2196F3",
  "KFD" = "#2196F3",
  "SFD" = "#2196F3",
  "SDAFD" = "#2196F3",
  "NLDFD" = "#2196F3",
  "PSDFD (Voss1998)" = "#2196F3",
  "PSDFD (Hasselman2013)" = "#2196F3",
  "HFD" = "#2196F3",
  "SVDEn" = "#E91E63",
  "K2En" = "#E91E63",
  "AttEn" = "#E91E63",
  "PhasEn (4)" = "#E91E63",
  "PhasEn (8)" = "#E91E63",
  "GridEn (3)" = "#E91E63",
  "GridEn (10)" = "#E91E63",
  "DiffEn" = "#E91E63",
  "DistrEn" = "#E91E63",
  "ApEn" = "#E91E63",
  "cApEn" = "#E91E63",
  "PEn" = "#E91E63",
  "WPEn" = "#E91E63",
  "SampEn" = "#E91E63",
  "FuzzyEn" = "#E91E63",
  "FuzzyApEn" = "#E91E63",
  "FuzzycApEn" = "#E91E63",
  "MSEn" = "#E91E63",
  "CMSEn" = "#E91E63",
  "RCMSEn" = "#E91E63",
  "MMSEn" = "#E91E63",
  "IMSEn" = "#E91E63",
  "MSApEn" = "#E91E63",
  "MSPEn" = "#E91E63",
  "CMSPEn" = "#E91E63",
  "MMSPEn" = "#E91E63",
  "IMSPEn" = "#E91E63",
  "MSWPEn" = "#E91E63",
  "CMSWPEn" = "#E91E63",
  "MMSWPEn" = "#E91E63",
  "IMSWPEn" = "#E91E63",
  "CPEn" = "#E91E63",
  "CWPEn" = "#E91E63",
  "CRPEn" = "#E91E63",
  "BubbEn" = "#E91E63",
  "CoSiEn" = "#E91E63",
  "MSCoSiEn" = "#E91E63",
  "IncrEn" = "#E91E63",
  "MSIncrEn" = "#E91E63",
  "SlopEn" = "#E91E63",
  "SlopEn (7)" = "#E91E63",
  "MSSlopEn" = "#E91E63",
  "SyDyEn" = "#E91E63",
  "MSSyDyEn" = "#E91E63",
  "MMSyDyEn" = "#E91E63",
  "DispEn" = "#E91E63",
  "DispEn (fluctuation)" = "#E91E63",
  "FuzzyMSEn" = "#E91E63",
  "FuzzyCMSEn" = "#E91E63",
  "FuzzyRCMSEn" = "#E91E63",
  "FuzzyMMSEn" = "#E91E63",
  "FuzzyIMSEn" = "#E91E63",
  "ShanEn (A)" = "#E91E63",
  "ShanEn (B)" = "#E91E63",
  "ShanEn (C)" = "#E91E63",
  "ShanEn (D)" = "#E91E63",
  "ShanEn (r)" = "#E91E63",
  "ShanEn (3)" = "#E91E63",
  "ShanEn (10)" = "#E91E63",
  "ShanEn (100)" = "#E91E63",
  "ShanEn (1000)" = "#E91E63",
  "CREn (A)" = "#E91E63",
  "CREn (B)" = "#E91E63",
  "CREn (C)" = "#E91E63",
  "CREn (D)" = "#E91E63",
  "CREn (r)" = "#E91E63",
  "CREn (3)" = "#E91E63",
  "CREn (10)" = "#E91E63",
  "CREn (100)" = "#E91E63",
  "CREn (1000)" = "#E91E63",
  "EnofEn (3)" = "#E91E63",
  "EnofEn (5)" = "#E91E63",
  "EnofEn (9)" = "#E91E63",
  "RangeEn" = "#E91E63",
  "SPEn (10)" = "#E91E63",
  "SPEn (50)" = "#E91E63",
  "SPEn (100)" = "#E91E63",
  "HEn" = "#E91E63",
  "KLEn" = "#E91E63",
  "KLEn (corrected)" = "#E91E63",
  "H" = "#2196F3",
  "LZC" = "#2196F3",
  "PLZC" = "#2196F3",
  "MSLZC" = "#2196F3",
  "MSPLZC" = "#2196F3",
  "RR" = "#2196F3",
  "FI" = "#FF5722",
  "FSI" = "#FF5722",
  "PowEn" = "#FF5722",
  "CD" = "#FF5722",
  "Hjorth" = "#FF5722",
  "LLE" = "#2196F3",
  "RQA (RecurrenceRate)" = "#4CAF50",
  "RQA (Determinism)" = "#4CAF50",
  "RQA (Laminarity)" = "#4CAF50",
  "RQA (TrappingTime)" = "#4CAF50",
  "RQA (DeteRec)" = "#4CAF50",
  "RQA (Divergence)" = "#4CAF50",
  "RQA (LamiDet)" = "#4CAF50",
  "RQA (L)" = "#4CAF50",
  "RQA (LEn)" = "#4CAF50",
  "RQA (VMax)" = "#4CAF50",
  "RQA (VEn)" = "#4CAF50",
  "RQA (W)" = "#4CAF50",
  "RQA (WMax)" = "#4CAF50",
  "RQA (WEn)" = "#4CAF50",
  "DFA" = "#4CAF50",
  "MFDFA (Fluctuation)" = "#4CAF50",
  "MFDFA (Width)" = "#4CAF50",
  "MFDFA (Peak)" = "#4CAF50",
  "MFDFA (Mean)" = "#4CAF50",
  "MFDFA (Max)" = "#4CAF50",
  "MFDFA (Delta)" = "#4CAF50",
  "MFDFA (Asymmetry)" = "#4CAF50",
  "MFDFA (Increment)" = "#4CAF50"
)

# length(unique(df$Index))
# unique(df$Index)[!unique(df$Index) %in% names(colors)]
# names(colors)[!names(colors) %in% unique(df$Index)]
```

### Computation Time


```{r message=FALSE, warning=FALSE, results='hide', echo=FALSE}
order <- df |>
  group_by(Index) |>
  summarize(Duration = median(Duration)) |>
  arrange(Duration) |>
  mutate(Index = factor(Index, levels = Index))

df <- mutate(df, Index = fct_relevel(Index, as.character(order$Index)))
```
```{r computationtime, echo=FALSE, fig.cap="Median computation time difference between the different complexity indices algorithms.", fig.height=10*1.25, fig.width=16*1.25, message=FALSE, warning=FALSE, cache=cache, include=FALSE, eval=FALSE}
p <- df |>
  filter(!Index %in% c("SD", "Length", "Noise", "Random", "Frequency")) |>
  mutate(Duration = Duration * 10000) |>
  ggplot(aes(x = Index, y = Duration)) +
  # geom_violin(aes(fill = Index)) +
  geom_hline(yintercept = 10**seq(0, 5, by = 2), linetype = "dotted", color = "#9E9E9E") +
  geom_hline(yintercept = 10**seq(1, 5, by = 2), color = "#9E9E9E") +
  ggdist::stat_slab(side = "bottom", aes(fill = Index), adjust = 3) +
  ggdist::stat_dotsinterval(aes(fill = Index, slab_size = NA)) +
  theme_modern() +
  scale_y_log10(breaks = 10**seq(0, 5), labels = function(x) sprintf("%g", x)) +
  scale_fill_manual(values = colors, guide = "none") +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1)) +
  labs(x = NULL, y = "Computation Time")
# ggsave("figures/computation_time-1.png", p, height=10*1.25, width=16*1.25)
p
```
```{r computationtime2, echo=FALSE, fig.cap="Median computation time difference between the different complexity indices algorithms.", fig.height=10*1.25, fig.width=16*1.25, message=FALSE, warning=FALSE, cache=FALSE, out.width="100%"}
knitr::include_graphics("figures/computation_time-1.png")
```


```{r time1, message=FALSE, warning=FALSE, include=FALSE, eval=FALSE}
dfsummary <- df |>
  filter(!Index %in% c("SD", "Length", "Noise", "Random", "Frequency")) |>
  mutate(Duration = Duration * 10000) |>
  group_by(Index, Length) |>
  summarize(
    CI_low = median(Duration) - sd(Duration),
    CI_high = median(Duration) + sd(Duration),
    Duration = median(Duration)
  )
dfsummary$CI_low[dfsummary$CI_low < 0] <- 0


dfsummary |>
  ggplot(aes(x = Index, y = Duration)) +
  # geom_hline(yintercept = c(0.001, 0.01, 0.1, 1), linetype = "dotted") +
  geom_hline(yintercept = 10**seq(0, 5, by = 2), linetype = "dotted", color = "#9E9E9E") +
  geom_line(aes(group = Length, color = Length)) +
  geom_hline(yintercept = 10**seq(1, 5, by = 2), color = "#9E9E9E") +
  # geom_point(aes(color = Length)) +
  theme_modern() +
  scale_y_log10(breaks = 10**seq(0, 5), labels = function(x) sprintf("%g", x)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1)) +
  guides(alpha = "none") +
  labs(y = "Time to compute", x = NULL, color = "Signal length")
```


```{r time2, message=FALSE, warning=FALSE, include=FALSE, eval=FALSE}
df |>
  filter(!Index %in% c("SD", "Length", "Noise", "Random", "Frequency")) |>
  mutate(Duration = Duration * 10000) |>
  ggplot(aes(x = as.factor(Length), y = Duration)) +
  # geom_hline(yintercept = c(0.001, 0.01, 0.1, 1), linetype = "dotted") +
  geom_line(data = dfsummary, aes(group = 1)) +
  geom_violin(aes(fill = Length)) +
  facet_wrap(~Index) +
  scale_y_log10(breaks = 10**seq(0, 4), labels = function(x) sprintf("%g", x)) +
  scale_fill_viridis_c(guide = "none") +
  theme_modern() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
```

Firstly, one should note that the computation times presented in **Figure 2** are relative and do not correspond to real times, as these would highly depend on the machine used. Rather, the goal here was to convey some intuition on the differences between different classes of indices (using the same machine and the same language of implementation, i.e., Python). While it is possible that computational advances or improvements in the code efficiency might change some of these values, we believe that the "big picture" should remain fairly stable, as it is to a large extent driven by the inherent nature of the algorithms under consideration.

Despite the relative shortness of the signals considered (a few thousand points at most), the fully-parallelized data generation script took about 24h to run on a 48-cores machine. After summarizing and sorting the indices by computation time, the most striking feature is the order of magnitude of difference between the fastest and slowest indices. Additionally, some indices are particularly sensitive to the signal length, a property which combined with computational cost led to indices being 100,000 times slower to compute than others.

In particular, multiscale indices were among the slowest to compute due to their iterative nature (a given index being computed multiple times on coarse-grained subseries of the signal). Indices related to Recurrence Quantification Analysis (RQA) were also relatively slow and did not scale well with signal length.



```{r message=FALSE, warning=FALSE, results='hide', echo=FALSE}
# Show and filter out NaNs
as.character(df[is.na(df$Result), "Index"])
df <- filter(df, !is.na(Result))

as.character(df[is.infinite(df$Result), "Index"])
df <- filter(df, !is.infinite(Result))

df <- df |>
  group_by(Index) |>
  standardize(select = "Result") |>
  ungroup()
```


<!-- ### Duplicates -->

```{r message=FALSE, warning=FALSE, fig.width=16, fig.height=15, cache=cache}
data <- df |>
  mutate(i = paste(Signal, Length, Noise_Type, Noise_Intensity, sep = "__")) |>
  select(i, Index, Result) |>
  pivot_wider(names_from = "Index", values_from = "Result") |>
  select(-i)

# pca <- principal_components(data, n=1) |>
#   arrange(desc(sign(PC1)), desc(abs(PC1)))

get_cor <- function(data, plot=FALSE) {
  cor <- correlation::correlation(data, method = "pearson", redundant = TRUE) |>
    correlation::cor_sort(hclust_method = "ward.D2")

  if(plot) {
    p_data <- cor |>
      cor_lower() |>
      mutate(
        Text = insight::format_value(r, zap_small = TRUE, digits = 3),
        Text = str_replace(str_remove(Text, "^0+"), "^-0+", "-"),
        Parameter2 = fct_rev(Parameter2)
      )

    p <- p_data |>
      ggplot(aes(x = Parameter2, y = Parameter1)) +
      geom_tile(aes(fill = r)) +
      # geom_text(aes(label = Text), size = 2) +
      scale_fill_gradient2(low = "#2196F3", mid = "white", high = "#F44336", midpoint = 0, limit = c(-1, 1), space = "Lab", name = "Correlation", guide = "legend") +
      scale_x_discrete(expand = c(0, 0)) +
      scale_y_discrete(expand = c(0, 0)) +
      labs(title = "Correlation Matrix of Complexity Indices", x = NULL, y = NULL) +
      theme_minimal() +
      theme(
        axis.text.x = element_text(angle = 90, hjust = 1),
        plot.title = element_text(hjust = 0.5, face="bold"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()
      )
    plot(p)
  }
  cor
}

cor <- get_cor(data)
```

```{r eval=TRUE, message=FALSE, warning=FALSE, include=FALSE, cache=cache}
cor |>
  cor_lower() |>
  filter(Parameter1 %in% names(data), Parameter2 %in% names(data)) |>
  arrange(desc(abs(r)), Parameter1) |>
  filter(Parameter1 != Parameter2) |>
  filter(abs(r) > .97) |>
  select(Parameter1, Parameter2, r)
```

```{r eval=FALSE, message=FALSE, warning=FALSE, cache=FALSE, include=FALSE}
# Duplicates
# ===========
averagetime <- arrange(summarize(group_by(df, Index), Duration = mean(Duration)), Duration)

filter(averagetime, Index %in% c("CREn (D)", "PFD (D)", "ShanEn (D)"))
filter(averagetime, Index %in% c("ShanEn (B)", "CREn (B)"))
filter(averagetime, Index %in% c("ShanEn (r)", "PFD (r)", "CREn (r)"))
filter(averagetime, Index %in% c("ShanEn (C)", "PFD (C)", "CREn (C)"))
filter(averagetime, Index %in% c("CREn (10)", "CREn (100)"))
filter(averagetime, Index %in% c("SVDEn", "FI"))
filter(averagetime, Index %in% c("PSDFD (Hasselman2013)", "PSDFD (Voss1998)"))
filter(averagetime, Index %in% c("MMSEn", "IMSEn"))
filter(averagetime, Index %in% c("H (corrected)", "H (uncorrected)"))
filter(averagetime, Index %in% c("FuzzyEn", "FuzzyApEn"))
filter(averagetime, Index %in% c("RCMSEn", "FuzzyRCMSEn"))
filter(averagetime, Index %in% c("SVDEn", "FuzzycApEn"))
filter(averagetime, Index %in% c("CPEn", "CRPEn"))
filter(averagetime, Index %in% c("NLDFD", "RR"))
```

For the subsequent analyses, we removed statistically redundant indices (which correlation was equal to 1.0), such as *PowEn* - identical to *SD*, *CREn (100)* - identical to *CREn (10)*, and *FuzzyRCMSEn* - identical to *RCMSEn*.


### Correlation

```{r correlation, message=FALSE, warning=FALSE, cache=cache, fig.width=16, fig.height=15, fig.cap="Correlation matrix of complexity indices."}
data <- data |>
  select(
    -`FuzzyRCMSEn`,
    -`CREn (100)`,
    -`PowEn`
  )


cor <- get_cor(data, plot=TRUE)
```

The Pearson correlation analysis revealed that complexity indices, despite their multitude and their conceptual specificities, do indeed share similarities. They form two major clusters that are easily observable (the blue and the red groups in **Figure 3**). That being said, these two anti-correlated groups are mostly revealing of the fact that some indices, by design, index the "predictability", whereas others, the "randomness", and thus are negatively related to one another. In order to extract finer groupings, further analyses procedures are applied below.

### Factor Analysis

```{r message=FALSE, warning=FALSE, cache=cache}
r <- correlation::cor_smooth(as.matrix(cor))
```
```{r nfactors, fig.cap="Agreement procedure for the optimal number of factors.", fig.height=7, fig.width=14, message=FALSE, warning=FALSE, include=FALSE, eval=TRUE, cache=cache}
n <- parameters::n_factors(data, cor = r, n_max=20)
n
plot(n) +
  see::theme_modern()
```


```{r message=FALSE, warning=FALSE}
selection <- c("ShanEn (D)",
               "NLDFD",
               "SVDEn",
               "AttEn",
               "MFDFA (Mean)",
               "MFDFA (Max)",
               "MFDFA (Increment)",
               "MFDFA (Width)",
               "FuzzyMSEn",
               "MSWPEn",
               "Hjorth",
               "CWPEn")
```

```{r loadings, message=FALSE, warning=FALSE, fig.width=12, fig.height=18, fig.cap="Factor loadings and computation times of the complexity indices, colored by the factor they represent the most."}
rez <- parameters::factor_analysis(data, cor = r, n = 14, rotation = "varimax", sort = TRUE, fm="mle")
# rez <- parameters::principal_components(data, n = 15, sort = TRUE)
# rez

col <- gsub('[[:digit:]]+', '', names(rez)[2])
closest <- colnames(select(rez, starts_with(col)))[apply(select(rez, starts_with(col)), 1, \(x) which.max(abs(x)))]


loadings <- attributes(rez)$loadings_long |>
  mutate(
    Loading = Loading,
    Component = fct_relevel(Component, rev(names(select(rez, starts_with(col))))),
    Variable = fct_rev(fct_relevel(Variable, rez$Variable))
  )

colors <- setNames(see::palette_material("rainbow")(length(levels(loadings$Component))), levels(loadings$Component))

# Sort by sign too
names(closest) <- rev(levels(loadings$Variable))

idx_order <- loadings |>
  mutate(Closest = closest[as.character(loadings$Variable)],
         Sign = sign(Loading)) |>
  filter(Component == Closest) |>
  arrange(desc(Component), desc(Sign), desc(abs(Loading))) |>
  pull(Variable) |>
  as.character()

separations <- table(closest)[intersect(levels(loadings$Component), unique(closest))]

face <- rep("plain", length(idx_order))
face[idx_order %in% c("SD", "Length", "Noise", "Random", "Frequency")] <- "italic"
face[idx_order %in% selection] <- "bold"


p1 <- loadings |>
  mutate(Variable = fct_relevel(Variable, rev(idx_order))) |>
  ggplot(aes(x = Variable, y = Loading)) +
  geom_bar(aes(fill = Component), stat = "identity") +
  geom_vline(xintercept = c("SD", "Length", "Noise", "Random", "Frequency"), color = "red") +
  geom_vline(xintercept = head(cumsum(separations), -1) + 0.5) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_material_d("rainbow") +
  coord_flip() +
  theme_minimal() +
  guides(fill = guide_legend(reverse = TRUE)) +
  labs(x = NULL) +
  theme(
    axis.text.y = element_text(
      color = rev(colors[closest]),
      face = rev(face),
      hjust = 0.5
    ),
    axis.text.x = element_blank(),
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )

p2 <- order |>
  mutate(Duration = 1 + Duration * 10000) |>
  filter(Index %in% loadings$Variable) |>
  mutate(Index = fct_relevel(Index, rev(idx_order)),
         Duration = ifelse(is.na(Duration), 0, Duration)) |>
  ggplot(aes(x = log10(Duration), y = Index)) +
  geom_bar(aes(fill = log10(Duration)), stat = "identity") +
  geom_hline(yintercept = head(cumsum(separations), -1) + 0.5) +
  scale_x_reverse(expand = c(0, 0)) +
  scale_y_discrete(position = "right") +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Computation Time", y = NULL) +
  theme_minimal() +
  theme(
    axis.text.y = element_blank(),
    axis.text.x = element_blank(),
    plot.title = element_text(hjust = 0.5),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )

(p2 | p1) + patchwork::plot_annotation(title = "Computation Time and Factor Loading", theme = theme(plot.title = element_text(hjust = 0.5, face = "bold")))
```

The agreement procedure for the optimal number of factors suggested that the 125 indices can be mapped on a multidimensional space of 14 orthogonal latent factors, that we extracted using a *varimax* rotation. We then took interest in the loading profile of each index, and in particular the latent dimension that it maximally relates to (see **Figure 4**).

The first extracted factor is the closest to the largest amount of indices, and is positively loaded by indices that are sensitive to the deviation of consecutive differences (e.g., *ShanEn - D*, *NLDFD*, *PFD - D*). In line with this, this factor was negatively loaded by indices related to Detrended Fluctuation Analysis (DFA), which tends to index the presence of long-term correlations. As such, this latent factor might encapsulate the predominance of short-term vs. long-term unpredictability.
The second factor was strongly loaded by signal *length* and *SD*, and thus might not capture features of complexity *per se*. Indices with the most relation to it were indices known to be sensitive to signal length, such as *ApEn*.
The third factor included multiscale indices, such as *MSWPEn*.
The fourth factor was loaded by permutation entropy indices, such as *WPEn*.
The fifth and the sixth factors were loaded by indices grouped by the signal symbolization method used (by a tolerance level *r*, or by the number of bins for the fifth and the sixth factors, respectively).
The seventh factor was loaded positively by the amount of noise, and negatively by multifractal indices such as *MFDFA - Increment*, suggesting a sensitivity to regularity.
Finally, as a manipulation check for our factorization method, the random vector did not load unto any factors.



### Hierarchical Clustering and Connectivity Network


```{r ggm, message=FALSE, warning=FALSE, fig.width=13, fig.height=13, fig.cap="Correlation network of the complexity indices. Only the links where |r| > 0.6 are displayed.", cache=cache}
library(ggraph)
extrafont::loadfonts()

g <- cor |>
  cor_lower() |>
  mutate(width = abs(r),
         edgecolor = as.character(sign(r))) |>
  filter(!Parameter1 %in% c("SD", "Length", "Random", "Frequency", "Noise"),
         !Parameter2 %in% c("SD", "Length", "Random", "Frequency", "Noise")) |>
  tidygraph::as_tbl_graph(directed=FALSE) |>
  mutate(importance = tidygraph::centrality_authority(weights = abs(r)),
         group = as.factor(tidygraph::group_louvain(weights = abs(r)))) |>
  tidygraph::activate("edges") |>
  filter(abs(r) > 0.6) |>
  tidygraph::activate("nodes") |>
  filter(!tidygraph::node_is_isolated()) |>
  mutate(colors = closest[name],
         selection = ifelse(name %in% selection, TRUE, FALSE))


p1 <- g |>
  ggraph(layout = 'linear', circular = TRUE) +  # fr # lgl # drl # kk
  ggraph::geom_edge_arc(aes(edge_width=width, edge_colour=edgecolor), alpha=0.66, strength=0.3) +
  # ggraph::geom_conn_bundle(aes(edge_width=width, edge_colour=edgecolor), alpha=0.66) +
  ggraph::geom_node_point(aes(size = importance)) +
  ggraph::geom_node_text(aes(x = x*1.05, y=y*1.05, label = name, angle = -((-node_angle(x, y)+90)%%180)+90, hjust='outward', color=selection)) +
  scale_edge_color_manual(values = c("1" = "#2E7D32", "-1"="#C62828"), guide = "none") +
  scale_edge_width_continuous(range = c(0.005, 0.66), guide = "none") +
  scale_size_continuous(range = c(0.1, 2), guide = "none") +
  scale_fill_material_d(guide= "none") +
  scale_colour_manual(values=c("TRUE" = "red", "FALSE"="black"), guide= "none") +
  ggtitle("Correlation Network") +
  ggraph::theme_graph() +
  theme(plot.title = element_text(face="bold", hjust=0.5)) +
  expand_limits(x = c(-1.25, 1.25), y = c(-1.25, 1.25))

p1
```



```{r clustering, message=FALSE, warning=FALSE, fig.width=13.4, fig.height=13.4, fig.cap = "Dendrogram representing the hierarchical clustering of the complexity indices.", cache=cache}
clust <- data |>
  select(-SD, -Length, -Random, -Frequency, -Noise) |>
  t() |>
  as.data.frame() |>
  dist() |>
  hclust(method = "ward.D2")


clusters <- cutree(clust, h = 150)
colors <- c("red", "black", see::palette_material("rainbow")(max(clusters)))
names(colors) <- c("TRUE", "FALSE", seq(1:max(clusters)))

dat <- clust |>
  create_layout(layout = 'dendrogram', circular = TRUE, repel=TRUE) |>
  attr("graph") |>
  tidygraph::activate("nodes") |>
  mutate(colors = closest[label],
         selection = ifelse(label %in% selection, TRUE, FALSE),
         cluster = as.factor(clusters[label]))


p2 <- dat |>
  tidygraph::activate("edges") |>
  mutate(height = as.data.frame(dat)$height[from]) |>
  ggraph(layout = 'dendrogram', circular = TRUE, repel=TRUE) +
  geom_edge_elbow(aes(edge_width = height)) +
  geom_node_point(aes(filter=leaf, color = cluster), size=3) +
  geom_node_text(aes(x = x*1.05, y=y*1.05, label = label, angle = -((-node_angle(x, y)+90)%%180)+90, hjust='outward', color = selection)) +
  scale_colour_manual(values=colors, guide= "none") +
  scale_edge_width_continuous(range=c(1, 1.15), guide= "none") +
  coord_fixed() +
  ggtitle("Hierarchical Clustering") +
  theme_graph() +
  theme(plot.title = element_text(face="bold", hjust=0.5)) +
  expand_limits(x = c(-1.25, 1.25), y = c(-1.25, 1.25))
# ggsave("figures/g.png", p2, width=13.4, height=13.4)
p2
```

For illustration purposes, we represented the correlation matrix as a connectivity graph (see **Figure 5**). We then ran a hierarchical clustering (with a Ward D2 distance) to provide additional information or confirmation about the groups discussed above. This allowed us to fine-grain our recommendations of complimentary complexity indices (see **Figure 6**).



### Indices Selection

The selection of a subset of indices was based on the following considerations: 1) high loadings on one predominant latent dimension, with additional attention to the pattern of secondary loadings. For instance, an index with a positive factor 1 loading and a negative factor 2 loading could complement another index with a similar factor 1 loading, but a positive factor 2 loading. This was helped by 2) the hierarchical clustering dendrogram, with which we attempted to indices from each (meaningful) higher order clusters. Items related to clusters that we know were related to noise, length or other artifacts were omitted. 3) A preference for indices with relatively shorter computation times. This yielded a selection of 12 indices. Next, we computed the cumulative variance explained of this selection in respect to the entirety of indices, and derived the optimal order to maximize the variance explained (see **Figure 7**). The 12 included indices, representing $91.01\%$ of the variance of the whole dataset, were:

- *ShanEn (D)*: The Shannon Entropy of the symbolic times series obtained by the "D" method described in @petrosian1995kolmogorov used traditionally in the context of the Petrosian fractal dimension [@esteller2001comparison]. The successive differences of the time series are assigned to 1 if the difference exceeds one standard deviation or 0 otherwise. The Entropy of the probabilities of these two events is then computed.
- *MSWPEn*: The Multiscale Weighted Permutation Entropy is the entropy of weighted ordinal descriptors of the time-embedded signal computed at different scales obtained by a coarsegraining procedure [@fadlallah2013weighted].
- *CWPEn*: The Conditional Weighted Permutation Entropy is based on the difference of weighted entropy between that obtained at an embedding dimension $m$ and that obtained at $m+1$ [@unakafov2014conditional].
- *FuzzyMSEn*: This index corresponds to the multiscale Fuzzy Sample Entropy [@ishikawa1979fuzzy]. This algorithm is computationally expensive to run.
- *AttEn*: The Attention Entropy is based on the frequency distribution of the intervals between the local maxima and minima of the time series [@yang2020classification].
- *NLDFD*: The Fractal dimension via Normalized Length Density (NLD) corresponds to the average absolute consecutive differences of the standardized signal [@kalauzi2009extracting].
- *Hjorth*: Hjorth's Complexity is defined as the ratio of the mobility of the first derivative of the signal to the mean frequency of the signal [@hjorth1970eeg].
- *MFDFA (Width)*: The width of the multifractal singularity spectrum [@kantelhardt2002multifractal] obtained via Detrended Fluctuation Analysis (DFA).
- *MFDFA (Max)* :  The value of singularity spectrum *D* corresponding to the maximum value of singularity exponent *H*.
- *MFDFA (Mean)* : The mean of the maximum and minimum values of singularity exponent *H*.
- *SVDEn*: Singular Value Decomposition (SVD) Entropy quantifies the amount of eigenvectors needed for an adequate representation of the signal [@roberts1999temporal].
- *MFDFA (Increment)*: The cumulative function of the squared increments of the generalized Hurst's exponents between consecutive moment orders [@faini2021multiscale].


```{r varexplained, echo=FALSE, fig.cap="Variance of the whole dataset of indices explained by the subselection. Each line represents a random number of selected variables. The red line represents the optimal order (i.e., the relative importance) that maximizes the variance explained. The dotted blue line represents the cumulative relative average computation time of the selected indices, and shows that FuzzyMSEn and MFDFA indices are the most costly algorithms.", fig.height=7, fig.width=10, message=FALSE, warning=FALSE, cache=cache}
dat <- select(data, -Random, -Frequency, -Noise, -Length, -SD)
SumCy <- sum(cov(dat), na.rm=TRUE)
varex <- data.frame()

get_r2 <- function(data, dat, SumCy) {
    Cx <- cov(data)
    Cxy <- cov(data, dat)
    solved <- tryCatch(solve(Cx), error = function(e) NULL)
    if (is.null(solved)) {
      return(NA)
      next
    } else {
      VAF <- t(Cxy) %*% solved %*% Cxy
      return(sum(VAF, na.rm=TRUE) / SumCy)
    }
}


optim <- data.frame()
final <- rep(NA, length(selection))
for(i in 1:length(selection)) {
  selec <- setdiff(selection, final)
  r2s <- rep(NA, length(selec))
  for(j in 1:length(selec)) {
    final[i] <- selec[j]
    temp <- final[!is.na(final)]
    r2s[j] <- get_r2(data[temp], dat, SumCy)
  }
  optim <- rbind(optim,
               data.frame(Order = i,
                          Index = selec,
                          VarEx = r2s))
  final[i] <- selec[which.max(r2s)]

}

varex <- data.frame()
for(iter in 1:500) {
  # cat(paste0(iter, " "))
  r2s <- rep(NA, length(selection))
  set.seed(iter)
  selec <- sample(selection)
  for(i in 1:length(selection)) {
    r2s[i] <- get_r2(data[selec[1:i]], dat, SumCy)
  }
  varex <- rbind(varex,
                 data.frame(Index = selec,
                            VarExplained = r2s,
                            CumVar = sum(r2s, na.rm=TRUE),
                            Order = 1:length(selection),
                            Iteration = as.character(iter)))
}

for(i in 1:length(selection)) {
  varex <- rbind(varex,
                 data.frame(Index = final[1:i],
                            VarExplained = get_r2(data[final[1:i]], dat, SumCy),
                            CumVar = max(optim$VarEx, na.rm=TRUE),
                            Order = i,
                            Iteration = "0"))
}


varex <- arrange(varex, desc(CumVar), Order)
selection <- varex[1:length(selection), "Index"]
higher <- varex[varex$Iteration == varex$Iteration[which(varex$VarExplained == max(varex$VarExplained, na.rm=TRUE))], ]

time <- order[order$Index %in% final, ]
time <- time[match(final, time$Index), ]
time[str_starts(time$Index, "MFDFA"), "Duration"] <- c(time[time$Index == "MFDFA (Width)",]$Duration, 0, 0, 0)
time$CumDuration <- cumsum(time$Duration)
time$VarExplained <- data_rescale(time$CumDuration, c(0.5, 0.95))
time$Order <- as.factor(1:nrow(time))

p5 <- varex |>
  mutate(Order = as.factor(Order)) |>
  ggplot(aes(x = Order, y=VarExplained)) +
  geom_line(aes(group=Iteration), color="black", alpha=0.05, size=0.3) +
  geom_line(aes(group=1), data=time, color="blue", alpha=0.5, size=1, linetype = "dotted") +
  geom_line(data=varex[varex$Iteration == "0", ], size=1, color="red") +
  annotate("label", x = 10, y = 0.5,
           label=paste0(
             c(paste0("Max. RÂ² = ",  insight::format_value(max(optim$VarEx, na.rm=TRUE), as_percent=TRUE)),
               paste0(1:length(selection), ": ", final)),
             collapse="\n"),
           color= "red", hjust=0, vjust=0, size=3) +
  labs(x = "Number of Selected Indices", y = "Variance Explaiend", title="Explanatory Power of Indices Subset") +
  scale_y_continuous(labels=scales::percent) +
  coord_cartesian(ylim=c(0.5, 0.95)) +
  theme_classic() +
  theme(plot.title = element_text(hjust=0.5, face="bold"))
# ggsave("figures/varexplained-1.png", p5, width=7, height=5)
p5
```

Finally, we visualized the expected value of our selection of indices for different types of signals under different conditions of noise (see **Figure 8**). This revealed that two indices, namely *ShanEn (D)* and *NLDFD*, are primarily driven by the noise intensity (which is expected, as they capture the variability of successive differences). The other indices appear to be able to discriminate between the various types of signals (when the signal is not dominated by noise).

```{r models, message=FALSE, warning=FALSE, fig.width=14, fig.height=7, fig.cap="Visualization of the expected value of a selection of indices depending on the signal type and of the amount of noise.", cache=cache}
model <- mgcv::gam(Result ~ s(Noise_Intensity, by = interaction(Index, Signal)),
            data=df |>
              filter(Index %in% selection) |>
              mutate(Noise_Type = as.factor(Noise_Type)))

estimate_means(model, at = c("Index", "Signal", "Noise_Intensity")) |>
  mutate(Index = fct_relevel(Index, final)) |>
  ggplot(aes(y = Mean, x = Noise_Intensity)) +
  geom_line(aes(color = Signal), size=1) +
  facet_wrap(~Index) +
  scale_linetype_manual(values = c("-2" = 3, "-1" = 4, "0" = 2, "1" = 5, "2" = 1)) +
  theme_classic() +
  scale_color_material("rainbow") +
  theme(panel.grid.major = element_line(colour = "#EEEEEE"),
        strip.background = element_blank()) +
  labs(y = "Standardized Index Value", x = "Noise Intensity", color = "Signal Type")
```


## Discussion

As the span and application of complexity science grows, a systematic approach to compare their "performance" becomes necessary to reinforce the clarity and structure of the field. The term *performance* is here to be understood in a relative sense, as any such endeavor faces the "hard problem" of complexity science: various objective properties of signals [e.g., short-term vs. long-term variability, auto-correlation, information, randomness, @namdari2019; @xiong2017] participate in forming together over-arching concepts such as "complex" and "chaotic". Indices that are sensitive to some of these objective properties are thus conceptually linked through these over-arching framework. However, it remains unclear how these high-level concepts transfer back, in a top-down fashion, into a combination of lower-level features. As such, it is conceptually complicated to benchmark complexity measures against "objectively" complex vs. non-complex signals. In other words, we know that different objective signal characteristics can contribute to the "complexity" of a signal, but there is not a one-to-one correspondence between the latter and the former.

To circumvent the aforementioned consideration, we adopted a paradigm where we generated different types of signals to which we systematically added distinct types - and amount - of perturbations. It is to note that  we did not seek at measuring how complexity indices can discriminate between these signal types, nor did we attempt at mimicking real-life signals or scenarios. The goal was instead to generate enough variability to reliably map the relationships between the indices.

Our results empirically confirm the plurality of underlying components of complexity (although it is here defined somewhat circularly as what is measured by complexity indices), and more importantly show that complexity indices vary in their sensitivity to various orthogonal latent dimensions. However, the limited possibilities of interpretation of these dimensions is a limitation of the present investigation, and future studies are needed to investigate and discuss them in greater depth (for instance, by modulating specific properties of signals and measuring their impact on these latent dimensions).

Taking into account the increasing role of complexity science as a field and the sheer number of complexity indices already published, our study aimed at empirically map the relationship between various indices and provide useful information to guide future researchers in their selection. Indices that were highlighted as encapsulating information about different underlying dimensions at a relatively low computational cost include *ShanEn (D)*, *MSWPEn*, *CWPEn*, *FuzzyMSEn*, *AttEn*, *NLDFD*, *Hjorth*, *MFDFA (Width)*, *MFDFA (Max)*, *MFDFA (Mean)*, *SVDEn*, *MFDFA (Increment)*. These indices might be complimentary in offering a comprehensive profile of the complexity of a time series. Moving forward, future studies are needed to validate, analyze and interpret the nature of the dominant sensitivities of indices groups, so that studies results can be more easily interpreted and integrated into new research and novel theories.


## Acknowledgments

We would like to thank the contributors of NeuroKit2, as well as the people that developed and shared open-source code which helped implementing the complexity algorithms in NeuroKit2. In particular, the contributors and maintainers of packages such as *nolds* [@scholzel2019nolds], *AntroPy* [@vallat2022antropy], *pyEntropy*, and *EntropyHub* [@flood2021entropyhub].

The study was funded partly by the Presidential Post-Doctoral Award to DM and Ministry of Education Academic Research Fund Tier 2 Grant (Project No.: MOE2019-T2-1-019) to AC. The authors declare no conflict of interest, and the funding sponsors had no role in the design, execution, interpretation or writing of the study.
