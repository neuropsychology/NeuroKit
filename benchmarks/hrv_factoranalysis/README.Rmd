---
output: 
  github_document:
    toc: false
    fig_width: 10.08
    fig_height: 6
tags: [r, hrv_factoranalysis]
vignette: >
  %\VignetteIndexEntry{README}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: bibliography.bib
csl: utils/apa.csl
---

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# options and parameters
options(digits=3)

knitr::opts_chunk$set(
  collapse = TRUE,
  dpi=450,
  fig.path = "figures/"
)

# Setup python - you need to change the path to your python distribution
library(reticulate)
reticulate::use_python("D:/Downloads/WPy64-3810/python-3.8.1.amd64/")
matplotlib <- import("matplotlib")
matplotlib$use("Agg", force = TRUE)
```




# The Factor Structure of Heart Rate Variability (HRV) Indices

*This study can be referenced by* [*citing the package*](https://github.com/neuropsychology/NeuroKit#citation).

**We'd like to publish this study, but unfortunately we currently don't have the time. If you want to help to make it happen, please contact us!**


## Introduction

The aim of this study is to explore the factor structure of HRV indices.


## Databases

We used the same databases as in [this study](https://github.com/neuropsychology/NeuroKit/tree/master/benchmarks/ecg_preprocessing#databases).




## Procedure

```{python, eval=FALSE}
import pandas as pd
import numpy as np
import neurokit2 as nk

# Load True R-peaks location
rpeaks_gudb = pd.read_csv("../../data/gudb/Rpeaks.csv")
rpeaks_mit1 = pd.read_csv("../../data/mit_arrhythmia/Rpeaks.csv")
rpeaks_mit2 = pd.read_csv("../../data/mit_normal/Rpeaks.csv")

datafiles = [rpeaks_gudb, rpeaks_mit1, rpeaks_mit2]

# Get results
all_results = pd.DataFrame()

for file in datafiles:
    for database in np.unique(file["Database"]):
        data = file[file["Database"] == database]
        for participant in np.unique(data["Participant"]):
            data_participant = data[data["Participant"] == participant]
            sampling_rate = np.unique(data_participant["Sampling_Rate"])[0]
            rpeaks = data_participant["Rpeaks"].values

            results = nk.hrv(rpeaks, sampling_rate=sampling_rate)
            results["Participant"] = participant
            results["Database"] = database
            results["Recording_Length"] = rpeaks[-1] / sampling_rate / 60

            all_results = pd.concat([all_results, results], axis=0)

all_results.to_csv("data.csv", index=False)
```

## Results


```{r, message=FALSE, warning=FALSE, results='hide'}
library(tidyverse)
library(easystats)

data <- read.csv("data.csv", stringsAsFactors = FALSE) %>% 
  select(-HRV_S, -HRV_SD1)  # Redundant
names(data) <- stringr::str_remove(names(data), "HRV_")
```

### Recording Length

#### Investigate effect

```{r, message=FALSE, warning=FALSE, results='hide'}
correlation(data) %>% 
  filter(Parameter2 == "Recording_Length") %>% 
  arrange(desc(abs(r)))
```

#### Adjust the data for recording length

```{r, message=FALSE, warning=FALSE, results='hide'}
data <- effectsize::adjust(data, effect="Recording_Length") %>% 
  select(-Recording_Length)
```

### Gaussian Graphical Model

```{r, message=FALSE, warning=FALSE, fig.width=17, fig.height=17}
library(ggraph)

data %>% 
  select(-ULF) %>%   # Empty 
  correlation::correlation(partial=FALSE) %>% 
  filter(abs(r) > 0.2) %>% 
  tidygraph::as_tbl_graph(directed=FALSE) %>% 
  dplyr::mutate(closeness = tidygraph::centrality_closeness(normalized = TRUE),
                degree = tidygraph::centrality_degree(normalized = TRUE),
                betweeness = tidygraph::centrality_betweenness(normalized = TRUE)) %>%
  tidygraph::activate(nodes) %>%
  dplyr::mutate(group1 = as.factor(tidygraph::group_edge_betweenness()),
                group2 = as.factor(tidygraph::group_optimal()),
                group3 = as.factor(tidygraph::group_walktrap()),
                group4 = as.factor(tidygraph::group_spinglass()),
                group5 = as.factor(tidygraph::group_louvain())) %>% 
  ggraph::ggraph(layout = "lgl") +
    ggraph::geom_edge_arc(aes(colour = r, edge_width = abs(r)), strength = 0.1, show.legend = FALSE) +
    ggraph::geom_node_point(aes(size = degree, color = group2), show.legend = FALSE) +
    ggraph::geom_node_text(aes(label = name), colour = "white") +
    ggraph::scale_edge_color_gradient2(low = "#a20025", high = "#008a00", name = "r") +
    ggraph::theme_graph() +
    guides(edge_width = FALSE) +
    scale_x_continuous(expand = expand_scale(c(.10, .10))) +
    scale_y_continuous(expand = expand_scale(c(.10, .10))) +
    scale_size_continuous(range = c(20, 30)) +
    scale_edge_width_continuous(range = c(0.5, 2)) +
    see::scale_color_material_d(palette="rainbow", reverse=TRUE)
```

Groups were identified using the [**tidygraph::group_optimal**](https://rdrr.io/cran/tidygraph/man/group_graph.html) algorithm.


### Factor Analysis


#### How many factors 

```{r, message=FALSE, warning=FALSE}
n <- parameters::n_factors(data[sapply(data, is.numeric)])

plot(n) +
  theme_modern()
```

#### Interpret

```{r, message=FALSE, warning=FALSE, fig.width=17, fig.height=17}
fa <- parameters::factor_analysis(data[sapply(data, is.numeric)], n=7, rotation="varimax")

print(fa, threshold="max", sort=TRUE)
```

<!-- #### Visualize -->

<!-- ```{r, message=FALSE, warning=FALSE, fig.width=17, fig.height=17} -->
<!-- plot(fa) -->
<!-- ``` -->


# References
